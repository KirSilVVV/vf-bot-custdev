# üìä Analytics Guide - AI Conversations & User Behavior

## üóÑÔ∏è Database Tables

### 1. **conversations** - –ò—Å—Ç–æ—Ä–∏—è –¥–∏–∞–ª–æ–≥–æ–≤ —Å AI
```sql
- user_id, user_name
- session_id (—É–Ω–∏–∫–∞–ª—å–Ω—ã–π ID –¥–∏–∞–ª–æ–≥–∞)
- message_number (–Ω–æ–º–µ—Ä —Å–æ–æ–±—â–µ–Ω–∏—è –≤ –¥–∏–∞–ª–æ–≥–µ: 1, 2, 3...)
- message_text (—á—Ç–æ –Ω–∞–ø–∏—Å–∞–ª –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å)
- ai_response (—á—Ç–æ –æ—Ç–≤–µ—Ç–∏–ª AI)
- ready_to_publish (true –∫–æ–≥–¥–∞ AI –ø—Ä–µ–¥–ª–æ–∂–∏–ª –æ–ø—É–±–ª–∏–∫–æ–≤–∞—Ç—å)
- published (true –µ—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –æ–ø—É–±–ª–∏–∫–æ–≤–∞–ª –∏–¥–µ—é)
- created_at
```

### 2. **requests** - –û–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–Ω—ã–µ –∏–¥–µ–∏
```sql
- user_id, user_name
- request_text (—Ñ–∏–Ω–∞–ª—å–Ω–∞—è –∏–¥–µ—è)
- vote_count (–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≥–æ–ª–æ—Å–æ–≤)
- channel_message_id
- created_at
```

### 3. **payments** - –ü–ª–∞—Ç–µ–∂–∏ –∑–∞ –∫–ª–∏–Ω–∏—á–µ—Å–∫–∏–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç
```sql
- user_id
- feature_id
- stars (–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–≤–µ–∑–¥)
- telegram_charge_id
- created_at
```

---

## üìà Useful Analytics Queries

### –°—Ä–µ–¥–Ω–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–æ–æ–±—â–µ–Ω–∏–π –¥–æ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏
```sql
SELECT AVG(message_number) as avg_messages_before_publish
FROM conversations 
WHERE ready_to_publish = true;
```

### –ö–æ–Ω–≤–µ—Ä—Å–∏—è (% –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –æ–ø—É–±–ª–∏–∫–æ–≤–∞–≤—à–∏—Ö –∏–¥–µ—é)
```sql
SELECT 
  COUNT(DISTINCT CASE WHEN published THEN session_id END) * 100.0 / 
  COUNT(DISTINCT session_id) as conversion_rate
FROM conversations;
```

### –¢–æ–ø –∞–∫—Ç–∏–≤–Ω—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π
```sql
SELECT 
  user_id, 
  user_name, 
  COUNT(DISTINCT session_id) as sessions,
  COUNT(*) as total_messages
FROM conversations 
GROUP BY user_id, user_name 
ORDER BY sessions DESC 
LIMIT 10;
```

### –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–∏–∞–ª–æ–≥–æ–≤ –ø–æ –¥–Ω—è–º
```sql
SELECT 
  DATE(created_at) as date,
  COUNT(DISTINCT session_id) as sessions
FROM conversations
GROUP BY DATE(created_at)
ORDER BY date DESC;
```

### Abandoned vs Completed Sessions
```sql
SELECT 
  CASE 
    WHEN published THEN 'Published' 
    ELSE 'Abandoned' 
  END as status,
  COUNT(DISTINCT session_id) as count
FROM conversations
WHERE ready_to_publish = true
GROUP BY published;
```

### –°–∞–º—ã–µ –ø–æ–ø—É–ª—è—Ä–Ω—ã–µ –∏–¥–µ–∏ (—Ç–æ–ø –ø–æ –≥–æ–ª–æ—Å–∞–º)
```sql
SELECT 
  r.id,
  r.user_name,
  r.request_text,
  r.vote_count,
  r.created_at
FROM requests r
ORDER BY r.vote_count DESC
LIMIT 10;
```

### Revenue –æ—Ç –∫–ª–∏–Ω–∏—á–µ—Å–∫–æ–≥–æ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–∞
```sql
SELECT 
  COUNT(*) as total_payments,
  SUM(stars) as total_stars,
  AVG(stars) as avg_stars_per_payment
FROM payments
WHERE kind = 'clinical_priority';
```

### Users who paid for priority
```sql
SELECT 
  p.user_id,
  COUNT(*) as payments,
  SUM(p.stars) as total_spent
FROM payments p
GROUP BY p.user_id
ORDER BY total_spent DESC;
```

---

## üöÄ Setup Instructions

### 1. Create conversations table in Supabase

1. Go to **Supabase Dashboard** ‚Üí Your Project
2. Click **SQL Editor** (left sidebar)
3. Click **New query**
4. Copy-paste content from `conversations.sql`
5. Click **Run** (or press Ctrl+Enter)
6. ‚úÖ Confirm: "Success. No rows returned"

### 2. Verify tables exist

```sql
SELECT table_name 
FROM information_schema.tables 
WHERE table_schema = 'public'
AND table_name IN ('conversations', 'requests', 'payments');
```

Should return 3 rows.

### 3. Test with sample data

Bot will automatically log conversations when users chat with AI.

---

## üìä Dashboard Ideas (Metabase/Retool/Excel)

### Key Metrics to Track:

1. **Engagement**
   - Total sessions per day/week
   - Average messages per session
   - Peak usage hours

2. **Conversion**
   - % of sessions that end with publication
   - % of ideas that get paid priority
   - Average time from start to publish

3. **Content Quality**
   - Most common problem keywords
   - Average idea length
   - Ideas with most votes

4. **Revenue**
   - Total Stars collected
   - Conversion rate to payment
   - Average Stars per active user

---

## üîç Example Workflow

1. User starts chat: `/start`
2. Sends idea: "–•–æ—á—É –∑–∞–ø–∏—Å–∞—Ç—å—Å—è –∫ –≤—Ä–∞—á—É –±—ã—Å—Ç—Ä–µ–µ"
3. AI asks: "–ö–∞–∫—É—é –∏–º–µ–Ω–Ω–æ –ø—Ä–æ–±–ª–µ–º—É —Ö–æ—á–µ—à—å —Ä–µ—à–∏—Ç—å?" ‚Üí **logged to conversations**
4. User replies: "–ù–µ—Ç –º–µ—Å—Ç –Ω–∞ –Ω–µ–¥–µ–ª—é –≤–ø–µ—Ä–µ–¥" ‚Üí **logged**
5. AI asks: "–ö–∞–∫ –≤–∏–¥–∏—à—å —Ä–µ—à–µ–Ω–∏–µ?" ‚Üí **logged**
6. User replies: "–õ–∏—Å—Ç –æ–∂–∏–¥–∞–Ω–∏—è" ‚Üí **logged with ready_to_publish=true**
7. User clicks "–û–ø—É–±–ª–∏–∫–æ–≤–∞—Ç—å" ‚Üí **published=true updated**
8. Idea posted to channel ‚Üí **saved to requests table**

Now you can analyze:
- How many questions AI asked (check message_number)
- What problems users mentioned (search in message_text)
- Conversion rate (published sessions / total sessions)

---

## üéØ A/B Testing System Prompts

Want to test different AI approaches?

1. Create `system_prompt_variant` column in conversations
2. Log which prompt version was used
3. Compare conversion rates:

```sql
SELECT 
  system_prompt_variant,
  COUNT(DISTINCT session_id) as sessions,
  COUNT(DISTINCT CASE WHEN published THEN session_id END) * 100.0 / 
    COUNT(DISTINCT session_id) as conversion_rate
FROM conversations
GROUP BY system_prompt_variant;
```

This helps you optimize AI behavior based on data! üìà
